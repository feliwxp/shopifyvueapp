{"version":3,"sources":["/app/packages/framework/src/ai/index.ts"],"sourcesContent":["import { Readable } from \"stream\";\n\nasync function* transform(stream: AsyncIterable<any>) {\n  for await (const part of stream) {\n    const content = part.choices?.[0]?.delta?.content ?? part.choices?.[0]?.text;\n    if (content) {\n      yield content;\n    }\n  }\n}\n\n/**\n * Converts the result of calling openai with `stream: true` into a readable stream that\n * Fasitfy can respond with.\n *\n *\n * @param {AsyncIterable<any>} stream - An AsyncIterable containing OpenAI response parts.\n * @returns {Readable} A Readable stream with the transformed content from the input stream.\n *\n *\n * @example\n * // Using the openAIResponseStream function to convert an AsyncIterable into a Readable stream\n * const stream = await connections.openai.chat.completions.create({\n *   model: \"gpt-3.5-turbo\",\n *   messages: [{ role: \"user\", content: \"Hello!\" }],\n *   stream: true,\n * });\n * await reply.send(openAIResponseStream(stream));\n *\n * @see {@link https://github.com/openai/openai-node} - OpenAI Node.js client library.\n * @see {@link https://docs.gadget.dev/guides/http-routes/route-configuration#sending-responses} - Sending responses in Gadget.\n */\nexport function openAIResponseStream(stream: AsyncIterable<any>) {\n  return Readable.from(transform(stream));\n}\n"],"names":["openAIResponseStream","transform","stream","part","content","choices","delta","text","Readable","from"],"mappings":";;;;+BAgCgBA;;aAAAA;;;yBAhCS;;;;;;AAEzB,gBAAgBC,UAAUC,MAA0B,EAAE;IACpD,WAAW,MAAMC,QAAQD,OAAQ;QAC/B,MAAME,UAAUD,KAAKE,OAAO,EAAE,CAAC,EAAE,EAAEC,OAAOF,WAAWD,KAAKE,OAAO,EAAE,CAAC,EAAE,EAAEE;QACxE,IAAIH,SAAS;YACX,MAAMA;QACR,CAAC;IACH;AACF;AAuBO,SAASJ,qBAAqBE,MAA0B,EAAE;IAC/D,OAAOM,kBAAQ,CAACC,IAAI,CAACR,UAAUC;AACjC"}